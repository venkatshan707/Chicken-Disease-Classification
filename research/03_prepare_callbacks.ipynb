{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* software development, especially in frameworks like TensorFlow or Keras for building neural networks, \"callbacks\" are functions that are called at specific points during the training of a model. These callbacks serve various purposes, such as logging information, saving model checkpoints, adjusting learning rates dynamically, or stopping training early based on certain conditions.\n",
    "\n",
    "* \"Prepare callbacks\" typically refer to a subset of callbacks that are invoked before the training begins. They allow you to set up the environment or configure certain aspects of the training process. Here are some common tasks that \"prepare callbacks\" might handle\n",
    "\n",
    "1. Data Preprocessing: Callbacks can be used to preprocess the data before feeding it into the model. This might involve normalization, resizing, or any other preprocessing steps necessary to prepare the data for training.\n",
    "\n",
    "2. Model Initialization: You might want to initialize the model or its parameters in a specific way before training begins. Callbacks can be used to perform such initialization tasks.\n",
    "\n",
    "3. Setting up Logging: Callbacks can set up logging mechanisms to track various metrics during training, such as loss, accuracy, or any other custom metrics.\n",
    "\n",
    "4. Preparing Learning Rate Schedules: If you plan to use learning rate schedules during training (e.g., decreasing the learning rate over time), you can set up these schedules using callbacks before training starts.\n",
    "\n",
    "5. Configuring Early Stopping Criteria: Callbacks can be used to configure early stopping criteria based on validation metrics. This allows you to stop training early if the model's performance on a validation set doesn't improve after a certain number of epochs.\n",
    "\n",
    "6. Setting up Checkpointing: Callbacks can configure the model to save checkpoints at regular intervals during training. These checkpoints can be used to resume training from a specific point or to evaluate the model's performance on unseen data.\n",
    "\n",
    "By using \"prepare callbacks,\" you can customize the training process and ensure that everything is set up correctly before the actual training begins. This modular approach enhances the flexibility and extensibility of the training process, allowing you to tailor it to your specific requirements.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When ever we are creating a model, it will save the metadata on the callbacks folders. When you lauch the tensorboard , you can see the Training graph, how it performing, what is the error ? we can even find the best model out of many epochs. If your model's performance not improving after some point when doing traing we can stop the traing at that point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\karth\\\\Documents\\\\EtE_prj\\\\Chicken-Disease-Classification'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'Chicken-Disease-Classification'\n",
      "c:\\Users\\karth\\Documents\\EtE_prj\\Chicken-Disease-Classification\\research\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karth\\.conda\\envs\\chicken\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "cd \"Chicken-Disease-Classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "#creating entity for call back folder configuration\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard_root_log_dir: Path\n",
    "    checkpoint_model_filepath: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        create_directories([\n",
    "            Path(model_ckpt_dir),\n",
    "            Path(config.tensorboard_root_log_dir)\n",
    "        ])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath=Path(config.checkpoint_model_filepath)\n",
    "        )\n",
    "\n",
    "        return prepare_callback_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareCallback:\n",
    "    def __init__(self, config: PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def _create_tb_callbacks(self): # When running code at some time, it will create a folder with that timestamp and stores the logs \n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\") #Getting timestamp\n",
    "        tb_running_log_dir = os.path.join(\n",
    "            self.config.tensorboard_root_log_dir,\n",
    "            f\"tb_logs_at_{timestamp}\",# creating a folder with name which contains timestamp\n",
    "        )\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def _create_ckpt_callbacks(self): # It creates a folder and saves check points for a model \n",
    "        return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(self.config.checkpoint_model_filepath),\n",
    "            save_best_only=True\n",
    "        )\n",
    "\n",
    "# If you wanna get out of checkpoints you can get it from here \n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        return [\n",
    "            self._create_tb_callbacks,\n",
    "            self._create_ckpt_callbacks\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-03 12:37:32,261:INFO:common:yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-03 12:37:32,269:INFO:common:yaml file: params.yaml loaded successfully]\n",
      "[2023-12-03 12:37:32,272:INFO:common:created directory at: artifacts]\n",
      "[2023-12-03 12:37:32,274:INFO:common:created directory at: artifacts\\prepare_callbacks\\checkpoint_dir]\n",
      "[2023-12-03 12:37:32,276:INFO:common:created directory at: artifacts\\prepare_callbacks\\tensorboard_log_dir]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tb_logs_at_2023-12-03-12-57-13'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\") #Getting timestamp\n",
    "f\"tb_logs_at_{timestamp}\" # Creating folder with tb_logs_at + Timestamp attached"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chicken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
